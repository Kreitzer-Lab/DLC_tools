{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Meeting 10/2/20: \n",
    "\n",
    "## Can we use deep learning to detect grooming bouts in videos?   \n",
    "___   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION: \n",
    "  \n",
    "## Convolutional Neural Networks (CNNs) have had great success in learning to categorize images \n",
    "## Can we use them to categorize higher-order behaviors? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lab_meeting/CNN_example.jpeg\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One cool idea is to transform data into images for training with CNNs: \n",
    "### Here's an example of spectrograms that were fed into a CNN for categorization\n",
    "<img src=\"lab_meeting/sound_examples.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# I tried to do something similar with behavior using some example videos from Robyn\n",
    "## I started making some tools along the way that could be helpful for the lab\n",
    "\n",
    ">### OUTLINE:\n",
    "- ### **STEP 1: Clean the data**\n",
    "- ### **STEP 2: Create a training set**\n",
    "- ### **STEP 3: Train a neural network (cloud computing with google colab notebook)**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video clips: grooming vs. locomotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mpy\n",
    "fps = 70\n",
    "frame_st = 46100\n",
    "frame_ed = 46400\n",
    "clip = mpy.VideoFileClip(\"RS07082020b_08182020_frameLabeled.mp4\")\n",
    "clip = clip.subclip(frame_st/fps,frame_ed/fps).resize(height=360)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 70\n",
    "frame_st = 500\n",
    "frame_ed = 800\n",
    "clip = mpy.VideoFileClip(\"RS07082020b_08182020_frameLabeled.mp4\")\n",
    "clip = clip.subclip(frame_st/fps,frame_ed/fps).resize(height=360)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Idea is to create images from behaviors\n",
    "## Example: grooming vs. locomotion\n",
    "*2s timelapsed traces for each body part*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"> \n",
    "\n",
    "### Grooming\n",
    "<img src=\"lab_meeting/groom.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### Locomotion\n",
    "<img src=\"lab_meeting/locomotion.png\" width=\"500\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # STEP 1: CLEAN THE DATA\n",
    "- ## Data from DeepLabCut often contains many labeling errors. \n",
    "- ### *Whether using B-SOID or an alternative, it is critical to feed in as high quality data as possible*  \n",
    "    - *Note: Do everything you can as early as possible in the pipeline to fix labeling errors* (**ideally at acquisition**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example clip with labeling errors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 70\n",
    "frame_st = 1200\n",
    "frame_ed = 1500\n",
    "clip = mpy.VideoFileClip(\"RS07082020b_08182020_frameLabeled.mp4\")\n",
    "clip = clip.subclip(frame_st/fps,frame_ed/fps).resize(height=360)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# A tool for cleaning DeepLabCut data:\n",
    "### Create a DataCleaner Object and import DLC data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaner import *\n",
    "D = DataCleaner('RS07082020b_08182020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This creates a pandas dataframe for x,y coordinates and confidence ratings based on your DeepLabCut results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I also included handy access to frame-by-frame displacements:**\n",
    "\n",
    "*(Number of pixels that each label moves per frame*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.disp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can take advantage of functionality built into pandas**\n",
    "\n",
    "For example, the describe() method gives quick overview of stats (front of mouse is faster than back which makes sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displacement statistics: \n",
    "D.disp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of mislabeled frames from video example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show x and y plots for the clip where the jump exists\n",
    "import matplotlib.pyplot as plt\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(D.x['pawFL'][frame_st:frame_ed],'r.-')\n",
    "axes[0].set_title('PawFL: X-coord')\n",
    "axes[0].set_xlabel('Frame Number')\n",
    "axes[0].set_ylabel('Pixel Number')\n",
    "axes[1].plot(D.y['pawFL'][frame_st:frame_ed],'r.-')\n",
    "axes[1].set_title('PawFL: Y-coord')\n",
    "axes[1].set_xlabel('Frame Number')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset:\n",
    "### *Displacement plot for the entire session:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show displacement heat map:\n",
    "import seaborn as sns\n",
    "yticks = [x for x in range(0,D.disp.shape[0],20000)]\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = sns.heatmap(D.disp,vmin=0,vmax=50,xticklabels = D.body_parts,yticklabels = yticks)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_title('Displacement')\n",
    "ax.set_ylabel('Frame Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low confidence frames (based on DeepLabCut results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of likelihoods for each bodypart: \n",
    "fig,axes = plt.subplots(1,1,figsize=(8,4))\n",
    "sns.distplot(D.conf.iloc[:,2],kde=False,bins=20,color='red')\n",
    "axes.set_ylabel('')\n",
    "axes.set_title('Histogram of Confidence Rating for pawFL')\n",
    "axes.set_ylim(0,50000)\n",
    "axes.set(yticklabels=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Built-in methods to clean the data:\n",
    "### Remove low confidence frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.remove_low_likelihood(.1) # Remove any label with confidence < 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display removed frames: (don't show scale)\n",
    "yticks = [x for x in range(0,D.disp.shape[0],20000)]\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = sns.heatmap(D.x.isnull(),xticklabels = D.body_parts,yticklabels = yticks, cbar=False)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_title('Display Removed Frames')\n",
    "ax.set_ylabel('Frame Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove frames where large jumps are detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.remove_jumps(40) # Remove any jumps creater than 40 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results:\n",
    "D_old = DataCleaner('RS07082020b_08182020.csv')\n",
    "yticks = [x for x in range(0,D.disp.shape[0],20000)]\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "sns.heatmap(D_old.disp,vmin=0,vmax=50,xticklabels=D.body_parts,yticklabels=yticks, ax=axes[0])\n",
    "sns.heatmap(D.disp,vmin=0,vmax=50,xticklabels=D.body_parts,yticklabels=yticks, ax=axes[1])\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_title('Original Version')\n",
    "axes[0].set_ylabel('Frame Number')\n",
    "axes[1].set_yticks(yticks)\n",
    "axes[1].set_title('Cleaned Version')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display cleaned example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(D_old.x['pawFL'][frame_st:frame_ed],'r.',markersize=5)\n",
    "axes[0].plot(D.x['pawFL'][frame_st:frame_ed],'b')\n",
    "axes[0].set_title('PawFL: X-coord')\n",
    "axes[0].set_ylabel('Pixel Number')\n",
    "axes[0].set_xlabel('Frame Number')\n",
    "axes[1].plot(D_old.y['pawFL'][frame_st:frame_ed],'r.',markersize=5)\n",
    "axes[1].plot(D.y['pawFL'][frame_st:frame_ed],'b')\n",
    "axes[1].set_title('PawFL: Y-coord')\n",
    "axes[1].set_xlabel('Frame Number')\n",
    "axes[1].legend(['Original','Corrected'],bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to a new .csv file in the orignal DLC format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.write_csv('RS07082020b_08182020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another useful tool: removing frames where labels get swapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_st = 1200\n",
    "frame_ed = 1500\n",
    "from DataCleaner import *\n",
    "import matplotlib.pyplot as plt\n",
    "D = DataCleaner('RS07082020b_08182020.csv')\n",
    "D.remove_low_likelihood(.1) # Remove any label with confidence < 10%\n",
    "D.remove_body_swaps() # Remove frames that jump close to other body parts\n",
    "D.interpolate()\n",
    "\n",
    "# plot results:\n",
    "D_old = DataCleaner('RS07082020b_08182020.csv')\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(D_old.x['pawFL'][frame_st:frame_ed],'r.',markersize=5)\n",
    "axes[0].plot(D.x['pawFL'][frame_st:frame_ed],'b')\n",
    "axes[0].set_title('PawFL: X-coord')\n",
    "axes[0].set_ylabel('Pixel Number')\n",
    "axes[0].set_xlabel('Frame Number')\n",
    "axes[1].plot(D_old.y['pawFL'][frame_st:frame_ed],'r.',markersize=5)\n",
    "axes[1].plot(D.y['pawFL'][frame_st:frame_ed],'b')\n",
    "axes[1].set_title('PawFL: Y-coord')\n",
    "axes[1].set_xlabel('Frame Number')\n",
    "axes[1].legend(['Original','Corrected'],bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning methods are still a work in progress:\n",
    "- ### This is just a first-pass attempt\n",
    "    - It still doesn't handle cases very well where large chunks of contiguous frames are mislabeled\n",
    "- ### There are probably unique problems related to each experiment\n",
    "    - Occlusion (position of camera)\n",
    "    - quality of video (lighting, focus, exposure)\n",
    "    - difficult to label body parts\n",
    "\n",
    "- ### Please try out some of these tools! That is the only way they will improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Adding a label for grooming bouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include label column\n",
    "df_labels = pd.read_csv('grooming_labels.csv')\n",
    "labels = np.zeros([D.disp.shape[0],1])\n",
    "for bout in range(df_labels.shape[0]):\n",
    "    labels[df_labels['Start'][bout]:df_labels['End'][bout]] = 1e6\n",
    "D.disp['grooming'] = labels\n",
    "\n",
    "\n",
    "# Make plot:\n",
    "yticks = [x for x in range(0,D.disp.shape[0],20000)]\n",
    "fig,axes = plt.subplots(1,1,figsize=(8,4))\n",
    "sns.heatmap(D.disp,vmin=0,vmax=50,xticklabels=D.disp.columns,yticklabels=yticks)\n",
    "axes.set_yticks(yticks)\n",
    "axes.set_title('Displacement with Grooming Bouts')\n",
    "axes.set_ylabel('Frame Number')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "> # STEP 2: Create a set of training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lab_meeting/test.png\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Lots of decisions need to be made here for optimization: \n",
    "    - Length of each video segment (depends on timescale of behaviors we care about) (2s used here, 1s sliding window)\n",
    "    - How to include velocity information (color coded here)\n",
    "    - How large of a training set do we need? \n",
    "        - Do we need data augmentation? What is the best way to do that? \n",
    "    - Need careful testing of parameter space to fine tune the model\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # STEP 3: Train Neural Network (Cloud computing with google colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
